{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4evmUiG7WL0V57sOuORuQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sada95/IA/blob/master/text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz0FaFXvF0DQ"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers.experimental import preprocessing\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ypoafYJJElc",
        "outputId": "abe8ce9d-3a3d-4525-b2de-27978e29d560"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2w3fMDXJE0S",
        "outputId": "d9c28c29-9401-47ef-daf8-67815f115d98"
      },
      "source": [
        "# Read, then decode for py2 compat.\r\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\r\n",
        "# length of text is the number of characters in it\r\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI9R3k65JFBX",
        "outputId": "af3ffd84-4ae9-4285-a4cd-baad6629d8a8"
      },
      "source": [
        "# Take a look at the first 250 characters in text\r\n",
        "print(text[:250])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnxLbMKRJo0D",
        "outputId": "ebe050d7-5afb-4e40-b758-ade6c060cc53"
      },
      "source": [
        "# The unique characters in the file\r\n",
        "vocab = sorted(set(text))\r\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zMpuNhPJ2kl",
        "outputId": "44cee5a9-56e5-4861-dd5f-6a3646eda668"
      },
      "source": [
        "example_texts = ['abcdefg', 'xyz']\r\n",
        "\r\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\r\n",
        "chars"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN5fxCswJ2v5"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\r\n",
        "    vocabulary=list(vocab))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szdGC8P2Jo3F",
        "outputId": "b7c99a26-6ea8-4061-e563-93e7811f44b0"
      },
      "source": [
        "ids = ids_from_chars(chars)\r\n",
        "ids"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[41, 42, 43, 44, 45, 46, 47], [64, 65, 66]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KyeqygfJo7N"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\r\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLmLjL4TJpe7",
        "outputId": "24c0cce0-a385-4f4f-b64b-897861aa623a"
      },
      "source": [
        "chars = chars_from_ids(ids)\r\n",
        "chars"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWZJydjOJFEX",
        "outputId": "61c441ff-f4c9-400f-86f7-d74e21b2ca81"
      },
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV977NgnMhUN"
      },
      "source": [
        "def text_from_ids(ids):\r\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-6ciVjJMhiC",
        "outputId": "7346f865-3e29-49a7-e86a-3ad505d495a4"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\r\n",
        "all_ids"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([20, 49, 58, ..., 47, 10,  2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzDlNzytMhsn"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihkm3hSxMh3I",
        "outputId": "3d2fdae7-2886-40b8-d9cc-d09cc587b00f"
      },
      "source": [
        "for ids in ids_dataset.take(10):\r\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAZjoH7ZNxzC"
      },
      "source": [
        "seq_length = 100\r\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1MEJfCyNyAN",
        "outputId": "60a0395d-5909-4511-94e0-713b66c92b86"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\r\n",
        "\r\n",
        "for seq in sequences.take(1):\r\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy-YEpNPNyNT",
        "outputId": "9026a5ed-fef2-49fe-dbfa-1544e5566ad4"
      },
      "source": [
        "for seq in sequences.take(5):\r\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6cTnjANOXig"
      },
      "source": [
        "def split_input_target(sequence):\r\n",
        "    input_text = sequence[:-1]\r\n",
        "    target_text = sequence[1:]\r\n",
        "    return input_text, target_text"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJCBLir_OXxZ",
        "outputId": "a5615544-78f6-42b1-a8db-122334b4ea60"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OnKcpvgOX63"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPXDHvfzMiCf",
        "outputId": "0cc49320-4096-4a1e-b524-0dca6018728e"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\r\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\r\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-_4csawMiMk",
        "outputId": "74b18d4b-0f03-412b-da6a-b06158278311"
      },
      "source": [
        "#Créer des lots d'entraînement\r\n",
        "# Batch size\r\n",
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "# Buffer size to shuffle the dataset\r\n",
        "# (TF data is designed to work with possibly infinite sequences,\r\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\r\n",
        "# it maintains a buffer in which it shuffles elements).\r\n",
        "BUFFER_SIZE = 10000\r\n",
        "\r\n",
        "dataset = (\r\n",
        "    dataset\r\n",
        "    .shuffle(BUFFER_SIZE)\r\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\r\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\r\n",
        "\r\n",
        "dataset"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 64, 100), (64, 64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDe4PFdzP0oN"
      },
      "source": [
        "#Construire le modèle\r\n",
        "# Length of the vocabulary in chars\r\n",
        "vocab_size = len(vocab)\r\n",
        "\r\n",
        "# The embedding dimension\r\n",
        "embedding_dim = 256\r\n",
        "\r\n",
        "# Number of RNN units\r\n",
        "rnn_units = 1024"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2pFcJN6Ryhw"
      },
      "source": [
        "class MyModel(tf.keras.Model):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\r\n",
        "    super().__init__(self)\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\r\n",
        "                                   return_sequences=True, \r\n",
        "                                   return_state=True)\r\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\r\n",
        "\r\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\r\n",
        "    x = inputs\r\n",
        "    x = self.embedding(x, training=training)\r\n",
        "    if states is None:\r\n",
        "      states = self.gru.get_initial_state(x)\r\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\r\n",
        "    x = self.dense(x, training=training)\r\n",
        "\r\n",
        "    if return_state:\r\n",
        "      return x, states\r\n",
        "    else: \r\n",
        "      return x"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq0VPDqMP0wZ"
      },
      "source": [
        "model = MyModel(\r\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\r\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\r\n",
        "    embedding_dim=embedding_dim,\r\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}